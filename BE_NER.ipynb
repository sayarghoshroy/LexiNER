{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BE_NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNMZeyQhQcrnr4jUhvofiYZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/LexiNER/blob/main/BE_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFNcu2mWsxV0"
      },
      "source": [
        "# Getting content from a set of URLs"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDisMCIZs9YF"
      },
      "source": [
        "# Uncomment if boilerpipe3 does not exist\n",
        "# !pip install boilerpipe3\n",
        "from boilerpipe.extract import Extractor\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT3KKOXCz8Xr"
      },
      "source": [
        "import nltk\n",
        "# To Download punkt module:\n",
        "# nltk.download('punkt')\n",
        "import pickle\n",
        "import sys\n",
        "import re"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wySrEzltF2m",
        "outputId": "c2e55a44-7096-4eab-b9ac-eeeaf32bd8ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "url_list = ['https://eisamay.indiatimes.com/nation/let-commander-3-other-terrorists-killed-in-kashmir/articleshow/78599215.cms',\n",
        "            'https://eisamay.indiatimes.com/nation/india-records-74383-covid-19-cases-tally-crosses-70-lakh-mark/articleshow/78599510.cms',\n",
        "            'https://eisamay.indiatimes.com/nation/delhi-student-18-beaten-to-death-allegedly-over-relationship-with-girl/articleshow/78589618.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article11',\n",
        "            'https://eisamay.indiatimes.com/entertainment/cinema/sharpshooter-involved-in-2000-attack-on-rakesh-roshan-arrested/articleshow/78593074.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article4',\n",
        "            'https://eisamay.indiatimes.com/crime/two-men-allegedly-stabbed-tea-shop-worker-after-he-refused-to-give-them-a-cigarette-in-delhi/articleshow/78592505.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article8',\n",
        "            'https://eisamay.indiatimes.com/entertainment/cinema/corona-positive-bengali-legend-actor-soumitra-chatterjee-is-well-now/articleshow/78587347.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article7',\n",
        "            'https://eisamay.indiatimes.com/nation/kedarnath-helicopter-service-starts-890-use-chopper-on-first-day/articleshow/78590624.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article4',\n",
        "            'https://eisamay.indiatimes.com/world/5-killed-in-collision-between-plane-microlight-aircraft-in-france/articleshow/78596847.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article11',\n",
        "            'https://eisamay.indiatimes.com/nation/india-continued-to-report-a-decline-in-the-active-cases-of-the-coronavirus-govt/articleshow/78592214.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article9',\n",
        "            'https://eisamay.indiatimes.com/nation/ambulance-driver-who-ferried-200-bodies-of-covid-patients-since-march-dies-of-virus-in-delhi/articleshow/78601226.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article4']\n",
        "\n",
        "print(\"Number of URLs: \" + str(len(url_list)))\n",
        "content_collection = []\n",
        "# content_collection format\n",
        "# {'url': <article_URL>, 'content': <boilerpipe_content>}"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of URLs: 10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YFWV24Ctl5y",
        "outputId": "ee023dd4-0e3d-48f1-eb63-559a15335bdc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "failed_extraction_count = 0\n",
        "failed_URLs = []\n",
        "\n",
        "for idx in tqdm(range(len(url_list))):\n",
        "  url = url_list[idx]\n",
        "  try:\n",
        "    extractor = Extractor(extractor = 'ArticleExtractor', url = url)\n",
        "    content = str(extractor.getText())\n",
        "    # extractor.getText() returns a java lang string\n",
        "    content_collection.append({'url': url, 'content': content})\n",
        "  except Exception as e:\n",
        "    failed_extraction_count += 1\n",
        "    failed_URLs.append(url)\n",
        "    print(\"Error Extracting Page at \" + url)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Number of URL Contents Extracted Successfully = \" + str(len(url_list) - failed_extraction_count))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 10/10 [00:11<00:00,  1.17s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number of URL Contents Extracted Successfully = 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnkyAp2LyqbD"
      },
      "source": [
        "#### Framing Named Entity Recognition Rules:\n",
        "\n",
        "- Refer to this [resource for Bengali NER](http://cdn.iiit.ac.in/cdn/ltrc.iiit.ac.in/ner-ssea-08/drafts/1.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZXsjyFh0yXe"
      },
      "source": [
        "def clean(txt):\n",
        "  # Cleans Text for Custom Tokenization\n",
        "  # Removes English Characters and Numbers\n",
        "  \n",
        "  txt = txt.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"|\", \" | \").replace(\"।\", \" । \")\n",
        "  # In Bengali, । marks the end of a sentence\n",
        "  punc_list = '!\"#$&*+,.-/;?@\\^_~)('\n",
        "  # Removing a set of special characters\n",
        "  t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
        "  txt = txt.translate(t)\n",
        "  # Removing single quotes and backticks\n",
        "  t = str.maketrans(dict.fromkeys(\"'`\", \"\"))\n",
        "  txt = txt.translate(t)\n",
        "  return txt\n",
        "\n",
        "def regtok(txt):\n",
        "  txt = clean(txt)\n",
        "  regex = re.compile(r'(\\d+|\\s+|=|}}|\\|)')\n",
        "  tokens = [token.strip() for token in regex.split(txt) if token.strip() != '' and token.strip().isalnum() != True]\n",
        "  return tokens"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo5yfjjeubbl"
      },
      "source": [
        "loc_token_end = ['সরনী', 'রোড', 'স্ট্রিট', 'লেন', 'থানা', 'স্কুল', 'বিদ্যালয়', 'কলেজ', 'নদী', 'লেক', 'হ্রদ', 'সাগর', 'মহাসাগর', 'পাহাড়', 'পর্বত']\n",
        "loc_connect_end = ['নগর', 'গঞ্জ', 'গ্রাম', 'পুর', 'গড়']\n",
        "person_begin = ['শ্রী', 'শ্রীযুক্ত', 'ডঃ', 'মিঃ', 'মিস', 'মিসেস', 'বেগম', 'বিবি', 'মোঃ', 'ডাক্তার', 'ডক্টর', 'স্বামী', 'সৈয়দ', 'রেভারেন্ড', 'প্রফ', 'অধ্যাপক'] \n",
        "person_end = ['বাবু', 'দাদা', 'দা', 'সাহেব', 'কাকু']\n",
        "person_ref_end = ['রা', 'এরা', 'দের', 'কে']\n",
        "person_marker = ['ৎ', ' ँ']\n",
        "ltd_prev_end = ['পাবলিক', 'প্রাইভেট']\n",
        "limited = 'লিমিটেড'\n",
        "and_name = 'এণ্ড'\n",
        "and_end = ['সনস', 'সন', 'ডটার', 'ডটারস', 'ডটার্স ', 'কম্পানি', 'কোম্পানি']\n",
        "org_end = ['ইনস্টিটিউট', 'এন্টারপ্রাইস', 'কোম্পানি', 'কোম্পানি', 'কর্পোরেশন']\n",
        "\n",
        "def get_named_entities(text):\n",
        "  text = clean(text)\n",
        "  tokens = regtok(text)\n",
        "  size = len(tokens)\n",
        "  \n",
        "  tags = ['none' for idx in range(size)]\n",
        "  # default tag is 'none'\n",
        "\n",
        "  for idx in range(size):\n",
        "    token = tokens[idx]\n",
        "    if token in loc_connect_end:\n",
        "      if idx > 0 and tokens[idx - 1] != '|' and tokens[idx - 1] != '।':\n",
        "        tags[idx - 1] = 'loc'\n",
        "        tags[idx] = 'loc'\n",
        "        print(\"Location Found\")\n",
        "\n",
        "    if idx > 1 and token == limited and tokens[idx - 1] in ltd_prev_end:\n",
        "      tags[idx - 2] = 'org'\n",
        "      tags[idx - 1] = 'org'\n",
        "      tags[idx] = 'org'\n",
        "      print(\"Organization Found\")\n",
        "\n",
        "    if idx > 0 and idx < (size - 1) and token == and_name and tokens[idx + 1] in and_end:\n",
        "      tags[idx - 1] = 'org'\n",
        "      tags[idx] = 'org'\n",
        "      tags[idx + 1] = 'org'\n",
        "      print(\"Organization Found\")\n",
        "\n",
        "    if token in org_end:\n",
        "      if idx > 0 and tokens[idx - 1] != '|' and tokens[idx - 1] != '।':\n",
        "        tags[idx - 1] = 'org'\n",
        "        tags[idx] = 'org'\n",
        "        print(\"Organization Found\")\n",
        "\n",
        "    for init in loc_token_end:\n",
        "      if token.endswith(init):\n",
        "        tags[idx] = 'loc'\n",
        "        print(\"Location Found\")\n",
        "\n",
        "    for init in person_begin:\n",
        "      if token.startswith(init):\n",
        "        print(\"Person Found\")\n",
        "        tags[idx] = 'per'\n",
        "        if idx + 1 > size and tokens[idx + 1] != '|' and tokens[idx + 1] != '।':\n",
        "          tags[idx + 1] = 'per'\n",
        "\n",
        "    for init in person_end:\n",
        "      if token.endswith(init):\n",
        "        tags[idx] = 'per'\n",
        "        print(\"Person Found\")\n",
        "\n",
        "    for init in person_ref_end:\n",
        "      if token.endswith(init):\n",
        "        tags[idx] = 'per'\n",
        "        print(\"Person Found\")\n",
        "\n",
        "    for init in person_marker:\n",
        "      if init in token:\n",
        "        tags[idx] = 'per'\n",
        "        print(\"Person Found\")\n",
        "  \n",
        "  return tags\n",
        "\n",
        "for page in content_collection:\n",
        "  get_named_entities(str(page['content']))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTlH-emG8dBp"
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}