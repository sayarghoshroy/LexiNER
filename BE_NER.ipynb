{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BE_NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPU72FE94EtOp5o9Ke3c0xl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sayarghoshroy/LexiNER/blob/main/BE_NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFNcu2mWsxV0"
      },
      "source": [
        "# Getting content from a set of URLs"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wDisMCIZs9YF"
      },
      "source": [
        "# Uncomment if boilerpipe3 does not exist\n",
        "# !pip install boilerpipe3\n",
        "from boilerpipe.extract import Extractor\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT3KKOXCz8Xr"
      },
      "source": [
        "import nltk\n",
        "# To Download punkt module:\n",
        "# nltk.download('punkt')\n",
        "import pickle\n",
        "import sys\n",
        "import json\n",
        "import re"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3wySrEzltF2m",
        "outputId": "28b4f981-778a-43e8-f45e-de06134ef07b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "url_list = ['https://eisamay.indiatimes.com/nation/let-commander-3-other-terrorists-killed-in-kashmir/articleshow/78599215.cms',\n",
        "            'https://eisamay.indiatimes.com/nation/india-records-74383-covid-19-cases-tally-crosses-70-lakh-mark/articleshow/78599510.cms',\n",
        "            'https://eisamay.indiatimes.com/nation/delhi-student-18-beaten-to-death-allegedly-over-relationship-with-girl/articleshow/78589618.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article11',\n",
        "            'https://eisamay.indiatimes.com/entertainment/cinema/sharpshooter-involved-in-2000-attack-on-rakesh-roshan-arrested/articleshow/78593074.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article4',\n",
        "            'https://eisamay.indiatimes.com/crime/two-men-allegedly-stabbed-tea-shop-worker-after-he-refused-to-give-them-a-cigarette-in-delhi/articleshow/78592505.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article8',\n",
        "            'https://eisamay.indiatimes.com/entertainment/cinema/corona-positive-bengali-legend-actor-soumitra-chatterjee-is-well-now/articleshow/78587347.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article7',\n",
        "            'https://eisamay.indiatimes.com/nation/kedarnath-helicopter-service-starts-890-use-chopper-on-first-day/articleshow/78590624.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article4',\n",
        "            'https://eisamay.indiatimes.com/world/5-killed-in-collision-between-plane-microlight-aircraft-in-france/articleshow/78596847.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article11',\n",
        "            'https://eisamay.indiatimes.com/nation/india-continued-to-report-a-decline-in-the-active-cases-of-the-coronavirus-govt/articleshow/78592214.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article9',\n",
        "            'https://eisamay.indiatimes.com/nation/ambulance-driver-who-ferried-200-bodies-of-covid-patients-since-march-dies-of-virus-in-delhi/articleshow/78601226.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article4',\n",
        "            'https://eisamay.indiatimes.com/west-bengal-news/kolkata-news/wbtc-will-starts-tram-facility-for-pandle-hopping-in-durga-puja-2020/articleshow/78604463.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article4',\n",
        "            'https://eisamay.indiatimes.com/entertainment/cinema/happy-birthday-amitabh-bachchan-ajay-devgn-to-ayushmann-khurrana-celebs-wish-the-legend/articleshow/78602599.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article1',\n",
        "            'https://eisamay.indiatimes.com/nation/uttarakhand-queen-of-the-night-brahmakamal-blooming-in-off-season-stumps-many/articleshow/78603528.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article7',\n",
        "            'https://eisamay.indiatimes.com/west-bengal-news/kolkata-news/people-engaged-in-puja-shopping-during-corona-pandemic/articleshow/78605765.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article11',\n",
        "            'https://eisamay.indiatimes.com/nation/pm-narendra-modi-says-property-cards-scheme-historical-move-to-transform-rural-india/articleshow/78604053.cms?utm_source=recommended&utm_medium=referral&utm_campaign=article12']\n",
        "\n",
        "with open('news_urls.json', 'w+') as f:\n",
        "  json.dump(url_list, f)\n",
        "\n",
        "with open('news_urls.json', 'r+') as f:\n",
        "  url_list = json.load(f)\n",
        "\n",
        "url_list_wiki = ['https://bn.wikipedia.org/wiki/%E0%A6%AD%E0%A6%BE%E0%A6%B0%E0%A6%A4',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%AD%E0%A6%BE%E0%A6%B0%E0%A6%A4%E0%A7%87%E0%A6%B0_%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%BE%E0%A6%A3%E0%A7%80',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%95%E0%A6%B2%E0%A6%95%E0%A6%BE%E0%A6%A4%E0%A6%BE',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%A8%E0%A7%80%E0%A6%B2%E0%A6%97%E0%A6%BF%E0%A6%B0%E0%A6%BF_%E0%A6%B2%E0%A7%87%E0%A6%99%E0%A7%8D%E0%A6%97%E0%A7%81%E0%A6%B0',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%A4%E0%A7%87%E0%A6%B2%E0%A7%87%E0%A6%99%E0%A7%8D%E0%A6%97%E0%A6%BE%E0%A6%A8%E0%A6%BE',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%86%E0%A6%B8%E0%A6%BE%E0%A6%AE',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%B9%E0%A6%B0%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6%BE%E0%A6%A8%E0%A6%BE',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%B9%E0%A6%BF%E0%A6%AE%E0%A6%BE%E0%A6%9A%E0%A6%B2_%E0%A6%AA%E0%A7%8D%E0%A6%B0%E0%A6%A6%E0%A7%87%E0%A6%B6',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%95%E0%A6%B0%E0%A7%8D%E0%A6%A3%E0%A6%BE%E0%A6%9F%E0%A6%95',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%BE%E0%A6%B2%E0%A6%AF%E0%A6%BC%E0%A6%BE%E0%A6%B2%E0%A6%AE_%E0%A6%AD%E0%A6%BE%E0%A6%B7%E0%A6%BE',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%AA%E0%A6%B0%E0%A7%8D%E0%A6%A4%E0%A7%81%E0%A6%97%E0%A6%BE%E0%A6%B2',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%A8%E0%A7%87%E0%A6%A6%E0%A6%BE%E0%A6%B0%E0%A6%B2%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A8%E0%A7%8D%E0%A6%A1%E0%A6%B8',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%AB%E0%A7%8D%E0%A6%B0%E0%A6%BE%E0%A6%A8%E0%A7%8D%E0%A6%B8',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%AF%E0%A7%81%E0%A6%95%E0%A7%8D%E0%A6%A4%E0%A6%B0%E0%A6%BE%E0%A6%9C%E0%A7%8D%E0%A6%AF',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%9C%E0%A6%AE%E0%A7%8D%E0%A6%AE%E0%A7%81_%E0%A6%93_%E0%A6%95%E0%A6%BE%E0%A6%B6%E0%A7%8D%E0%A6%AE%E0%A7%80%E0%A6%B0',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%B8%E0%A7%81%E0%A6%87%E0%A6%9C%E0%A6%BE%E0%A6%B0%E0%A6%B2%E0%A7%8D%E0%A6%AF%E0%A6%BE%E0%A6%A8%E0%A7%8D%E0%A6%A1',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%87%E0%A6%A4%E0%A6%BE%E0%A6%B2%E0%A6%BF',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%85%E0%A6%B8%E0%A7%8D%E0%A6%9F%E0%A7%8D%E0%A6%B0%E0%A6%BF%E0%A6%AF%E0%A6%BC%E0%A6%BE',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%9C%E0%A6%BE%E0%A6%B0%E0%A7%8D%E0%A6%AE%E0%A6%BE%E0%A6%A8%E0%A6%BF',\n",
        "                 'https://bn.wikipedia.org/wiki/%E0%A6%AE%E0%A6%BE%E0%A6%A6%E0%A7%8D%E0%A6%B0%E0%A6%BF%E0%A6%A6']\n",
        "\n",
        "with open('wiki_urls.json', 'w+') as f:\n",
        "  json.dump(url_list_wiki, f)\n",
        "\n",
        "with open('wiki_urls.json', 'r+') as f:\n",
        "  url_list_wiki = json.load(f)\n",
        "\n",
        "print(\"Number of News URLs: \" + str(len(url_list)))\n",
        "print(\"Number of Wikipedia URLs: \" + str(len(url_list_wiki)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of News URLs: 15\n",
            "Number of Wikipedia URLs: 20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6YFWV24Ctl5y",
        "outputId": "767ef53b-44e5-41a3-e930-4b82fdf1dfa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "content_collection = []\n",
        "# content_collection format\n",
        "# {'url': <article_URL>, 'content': <boilerpipe_content>}\n",
        "\n",
        "failed_extraction_count = 0\n",
        "failed_URLs = []\n",
        "\n",
        "for idx in tqdm(range(len(url_list_wiki))):\n",
        "  url = url_list_wiki[idx]\n",
        "  try:\n",
        "    extractor = Extractor(extractor = 'ArticleExtractor', url = url)\n",
        "    content = str(extractor.getText())\n",
        "    # extractor.getText() returns a java lang string\n",
        "    content_collection.append({'url': url, 'content': content})\n",
        "  except Exception as e:\n",
        "    failed_extraction_count += 1\n",
        "    failed_URLs.append(url)\n",
        "    print(\"Error Extracting Page at \" + url)\n",
        "\n",
        "print(\"\")\n",
        "print(\"Number of URL Contents Extracted Successfully = \" + str(len(url_list_wiki) - failed_extraction_count))\n",
        "print(\"Set of Failed URLs: \")\n",
        "print(failed_URLs)\n",
        "\n",
        "with open('working_content.json', 'w+') as f:\n",
        "  json.dump(content_collection, f)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 20/20 [00:07<00:00,  2.62it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number of URL Contents Extracted Successfully = 20\n",
            "Set of Failed URLs: \n",
            "[]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnkyAp2LyqbD"
      },
      "source": [
        "#### Framing Named Entity Recognition Rules:\n",
        "\n",
        "- Refer to this [resource for Bengali NER](http://cdn.iiit.ac.in/cdn/ltrc.iiit.ac.in/ner-ssea-08/drafts/1.pdf)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZXsjyFh0yXe"
      },
      "source": [
        "def clean(txt):\n",
        "  # Cleans Text for Custom Tokenization\n",
        "  # Removes English Characters and Numbers\n",
        "\n",
        "  txt = txt.replace(\"\\n\", \" \").replace(\"\\r\", \" \").replace(\"|\", \" | \").replace(\"।\", \" । \")\n",
        "  # In Bengali, । marks the end of a sentence\n",
        "  punc_list = '!\"#$&*+,.-/;?@\\^_~)(][}{%'\n",
        "  # Removing a set of special characters\n",
        "  t = str.maketrans(dict.fromkeys(punc_list, \" \"))\n",
        "  txt = txt.translate(t)\n",
        "  # Removing single quotes and backticks\n",
        "  t = str.maketrans(dict.fromkeys(\"'`\", \"\"))\n",
        "  txt = txt.translate(t)\n",
        "  return txt\n",
        "\n",
        "def regtok(txt):\n",
        "  txt = clean(txt)\n",
        "  regex = re.compile(r'(\\d+|\\s+|=|}}|\\|)')\n",
        "  tokens = [token.strip() for token in regex.split(txt) if token.strip() != '' and token.strip().isalnum() != True]\n",
        "  return tokens"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo5yfjjeubbl",
        "outputId": "e734f5e9-7073-413d-9d3e-d5f5e10b3860",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "loc_token_end = ['সরনী', 'রোড', 'স্ট্রিট', 'লেন', 'থানা', 'স্কুল', 'বিদ্যালয়', 'কলেজ', 'নদী', 'লেক', 'হ্রদ', 'সাগর', 'মহাসাগর', 'পাহাড়', 'পর্বত']\n",
        "loc_connect_end = ['নগর', 'গঞ্জ', 'গ্রাম', 'পুর', 'গড়']\n",
        "person_begin = ['শ্রী', 'শ্রীযুক্ত', 'ডঃ', 'মিঃ', 'মিস', 'মিসেস', 'বেগম', 'বিবি', 'মোঃ', 'ডাক্তার', 'ডক্টর', 'স্বামী', 'সৈয়দ', 'রেভারেন্ড', 'প্রফ', 'অধ্যাপক', 'প্রধানমন্ত্রীর'] \n",
        "person_end = ['বাবু', 'দাদা', 'দা', 'সাহেব', 'কাকু']\n",
        "surnames = ['ঘোষ', 'বোস', 'বসু', 'মিত্র', 'রায়', 'সরকার', 'খান', 'আহমেদ', 'রহমান', 'হক']\n",
        "person_end += surnames\n",
        "person_ref_end = ['রা', 'এরা', 'দের', 'কে']\n",
        "person_marker = ['ৎ', ' ँ']\n",
        "ltd_prev_end = ['পাবলিক', 'প্রাইভেট']\n",
        "limited = 'লিমিটেড'\n",
        "and_name = 'এণ্ড'\n",
        "and_end = ['সনস', 'সন', 'ডটার', 'ডটারস', 'ডটার্স ', 'কম্পানি', 'কোম্পানি']\n",
        "org_end = ['ইনস্টিটিউট', 'এন্টারপ্রাইস', 'কোম্পানি', 'কোম্পানি', 'কর্পোরেশন']\n",
        "\n",
        "def get_named_entities(text):\n",
        "  text = clean(text)\n",
        "  tokens = regtok(text)\n",
        "  size = len(tokens)\n",
        "  \n",
        "  tags = ['none' for idx in range(size)]\n",
        "  # default tag is 'none'\n",
        "\n",
        "  left = 0\n",
        "  # marks the beginning of a possible arconym\n",
        "\n",
        "  for idx in range(size):\n",
        "    token = tokens[idx]\n",
        "    if token in loc_connect_end:\n",
        "      if idx > 0 and tokens[idx - 1] != '|' and tokens[idx - 1] != '।':\n",
        "        tags[idx - 1] = 'loc'\n",
        "        tags[idx] = 'loc'\n",
        "\n",
        "    if idx > 1 and token == limited and tokens[idx - 1] in ltd_prev_end:\n",
        "      tags[idx - 2] = 'org'\n",
        "      tags[idx - 1] = 'org'\n",
        "      tags[idx] = 'org'\n",
        "      print(\"Organization Found\")\n",
        "\n",
        "    if idx > 0 and idx < (size - 1) and token == and_name and tokens[idx + 1] in and_end:\n",
        "      tags[idx - 1] = 'org'\n",
        "      tags[idx] = 'org'\n",
        "      tags[idx + 1] = 'org'\n",
        "      print(\"Organization Found\")\n",
        "\n",
        "    if token in org_end:\n",
        "      if idx > 0 and tokens[idx - 1] != '|' and tokens[idx - 1] != '।':\n",
        "        tags[idx - 1] = 'org'\n",
        "        tags[idx] = 'org'\n",
        "        print(\"Organization Found\")\n",
        "\n",
        "    for init in loc_token_end:\n",
        "      if token.endswith(init):\n",
        "        tags[idx] = 'loc'\n",
        "\n",
        "    for init in person_begin:\n",
        "      if token.startswith(init):\n",
        "        tags[idx] = 'per'\n",
        "        if idx + 1 > size and tokens[idx + 1] != '|' and tokens[idx + 1] != '।':\n",
        "          tags[idx + 1] = 'per'\n",
        "\n",
        "    for init in person_end:\n",
        "      if token.endswith(init):\n",
        "        tags[idx] = 'per'\n",
        "\n",
        "    for init in person_ref_end:\n",
        "      if token.endswith(init):\n",
        "        tags[idx] = 'per'\n",
        "\n",
        "    for init in person_marker:\n",
        "      if init in token:\n",
        "        tags[idx] = 'per'\n",
        "\n",
        "    if len(token) <= 2 and token != '|' and token != '।':\n",
        "      pass\n",
        "    \n",
        "    elif len(token) > 2 or token == '|' or token == '।':\n",
        "      if idx - left <= 2:\n",
        "        left = idx + 1\n",
        "      else:\n",
        "        print(\"Organization Acronym Found\")\n",
        "        while left != idx:\n",
        "          print(tokens[left])\n",
        "          tags[left] = 'org'\n",
        "          left += 1\n",
        "        left = idx + 1\n",
        "  \n",
        "  return tags\n",
        "\n",
        "for page in content_collection:\n",
        "  get_named_entities(str(page['content']))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Organization Found\n",
            "Organization Found\n",
            "Organization Found\n",
            "Organization Found\n",
            "Organization Found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTlH-emG8dBp"
      },
      "source": [
        "# ^_^ Thank You"
      ],
      "execution_count": 8,
      "outputs": []
    }
  ]
}